{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Redes RBF - Exercicio</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32.7999, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "values_X = pd.DataFrame(load_boston().data, columns = boston.feature_names).values # importando as 13 variáveis\n",
    "values_Y = pd.DataFrame(boston.target).values #importando valores medios das casas ocupadas\n",
    "\n",
    "#Calculando a porcentagem do dataset que virá ser utilizado\n",
    "aux = values_X[:,1].shape\n",
    "N_total = aux[0]\n",
    "N = int(.8*N_total)\n",
    "\n",
    "#Pegando N linhas e atriuindo a uma varivel para treinamento\n",
    "x = values_X[:N,:]\n",
    "y_train = torch.from_numpy(values_Y[:N,:])\n",
    "bias = np.ones(y_train.shape)\n",
    "x_train= torch.from_numpy(np.concatenate((bias,x), axis=1))\n",
    "\n",
    "#Pegando o linhas a partir de N para variaveis de test\n",
    "test_y = torch.from_numpy(values_Y[N:,:])\n",
    "test_y.shape\n",
    "biasTest = np.ones(test_y.shape)\n",
    "values_testX = values_X[N:,:]\n",
    "test_X = torch.from_numpy(np.concatenate((biasTest,values_testX), axis=1))\n",
    "\n",
    "#Treinamento da regressão\n",
    "theta = torch.inverse(x_train.T @ x_train) @ x_train.T @ y_train\n",
    "test = test_X @ theta #Teste\n",
    "error = torch.mean((test_y - test )**2)#Calculo do erro quadratico medio\n",
    "\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Para implementacao do RBF primeiro escolhemos aleatoriamente os Centroides </h4> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ X = \\boxed{x^T_1\\\\x^T_2\\\\x^T_3\\\\\\vdots\\\\x^T_n} \\Longrightarrow C = \\boxed{x^T_1\\\\x^T_4\\\\\\vdots\\\\x^T_m} \\Longrightarrow C = \\boxed{c^T_1\\\\c^T_4\\\\\\vdots\\\\c^T_m}_m\\\\Levando\\ em\\ conta\\ que\\ m<n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Formando minha matriz Z</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Z = \\begin{bmatrix}\n",
    "||\\vec x_1-\\vec c_1||^2 && ||\\vec x_1-\\vec c_2||^2  && \\cdots && ||\\vec x_1-\\vec c_m||^2\\\\\n",
    "||\\vec x_2-\\vec c_1||^2  && ||\\vec x_2-\\vec c_2||^2  && \\cdots && ||\\vec x_2-\\vec c_m||^2\\\\ \n",
    "\\vdots && \\vdots && \\cdots && \\vdots \\\\\n",
    "||\\vec x_n-\\vec c_1||^2 && ||\\vec x_n-\\vec c_2||^2  && \\cdots && ||\\vec x_n-\\vec c_m||^2\n",
    "\\end{bmatrix}_{NxM}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$\\tilde{Z} \\leftarrow exp \t\\left \\{ -\\gamma Z\\right \\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h4>Aplicando modelo linear<h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{\\vec \\theta_{LS}} = (\\tilde{Z}^T\\tilde{Z})^{-1}\\tilde{Z}\\vec y $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[        inf,         inf,         inf,  ...,         inf,\n",
       "                 inf,         inf],\n",
       "        [        inf,         inf,         inf,  ...,         inf,\n",
       "                 inf,         inf],\n",
       "        [        inf,         inf,         inf,  ...,         inf,\n",
       "                 inf,         inf],\n",
       "        ...,\n",
       "        [        inf,         inf, 2.1307e+288,  ...,         inf,\n",
       "                 inf,         inf],\n",
       "        [        inf,         inf,         inf,  ...,         inf,\n",
       "                 inf,         inf],\n",
       "        [        inf,         inf,         inf,  ...,         inf,\n",
       "                 inf,         inf]], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import random\n",
    "numero_centroides = random.randint(N ,size=int(.6*N))\n",
    "C = x[numero_centroides]\n",
    "print(C.shape)\n",
    "gamma = (10^-4)\n",
    "Z = torch.cdist(torch.from_numpy(x),torch.from_numpy(C))\n",
    "Z = Z**2\n",
    "kernel = torch.exp(-gamma*Z)\n",
    "kernel.shape\n",
    "kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]], dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = kernel[:,1].shape\n",
    "N_linhas_Bias = aux[0]\n",
    "Bias_RBF = torch.ones(N_linhas_Bias).reshape(-1,1)\n",
    "kernel = torch.cat((Bias_RBF,kernel),1)\n",
    "theta_LS = torch.inverse(kernel.T @ kernel) @ kernel.T @ y_train\n",
    "theta_LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
